---
title: "RNAseq pipeline"
author: "Guide: Francisco Gil. Scripts: Nicolas Delhomme"
date: "31/08/2018"
output: 
  html_document:
    code_folding: hide

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Notes

This server works with the SLURM management program. It works by sending scripts to the server (sbatch script.sh)

Also some programs are implemented inside containers (sandboxes). In this case singularity images were used in some of the programs. Containers are useful for providing repetitiveness of the anaylisis.

## First step

Your files and databases (if required) need to be uploaded first to the server (It is advisable to upload them with integrity check)

SSH login into the server

## Quality Check

Script for FastQC:


submitFastQC.sh

<input type=button class=hideshow></input>
```{code: (;bash)}
#!/bin/bash -l

set -ex

proj=u2018012
mail=francisco.gil.munoz@slu.se

in=/mnt/picea/projects/dateplum/rgarcia/persimmon-rootstocks-salinity-tolerance/raw
out=/mnt/picea/projects/dateplum/rgarcia/persimmon-rootstocks-salinity-tolerance/fastqc/raw

module load bioinfo-tools FastQC

mkdir -p $out

if [ -z $UPSCb ]; then
    echo "Set up the UPSCb env. var. to your Git UPSCb checkout dir."
fi

for f in `find $in -name "*.fq.gz"`; 
do
  fnam=$(basename ${f/.fq.gz/})
  sbatch -A $proj --mail-user=$mail -e $out/$fnam.err -o $out/$fnam.out $UPSCb/pipeline/runFastQC.sh $out $f
done
```

```{runFastQC}
#!/bin/bash -l
#SBATCH -p core
#SBATCH -n 1
#SBATCH -t 3:00:00
#SBATCH --mail-type=ALL

## stop on error but be verbose
set -ex

##
#  Run fastQC 
usage(){
  echo >&2 \
  "Usage: $(basename $0) <outputFolder> <file> [file] ..."
  exit 1
}


## sanity checks
## executable
## are we on UPPMAX
if [ ! -z $SLURM_SUBMIT_DIR ]; then
	module load bioinfo-tools FastQC
##	echo "Running on UPPMAX"
else
##	echo "Running locally"
	fastqc=`which fastqc`
	if [ "$?" == "1" ]; then
		echo "please install fastqc before running this script or add it to your PATH"
		usage
	fi

	if [ ! -f $fastqc -a ! -x $fastqc ]; then
		echo "your fastQC does not appear to be an executable file"
		usage
	fi
fi

## arguments
if [ $# -lt 2 ]; then
   echo "This script takes two arguments"
   usage
fi

## input file
if [ ! -d $1 ]; then
	echo "The first argument needs to be an existing output directory."
	usage
fi
out=$1
shift

## output dir
for f in $@; do
  if [ ! -f $f ]; then
	echo "The second (and successive) arguments needs to be an existing fastq (optionally gz) file"
	usage
  fi
done

## start
fastqc --noextract --outdir $out $@ -t $SLURM_CPUS_ON_NODE

```


For running FastQC is not important to distinguish between forward and reverse sequences, so we omitted that identifier for the analysis in the script.

Remember **ALWAYS** to check permissions before running (ls -l for details)

For assigning permissions to execute:

``` {chmod}
chmod a+x {nameofthefile}

a -> all
+ -> add
x -> executing
```

With squeue we can follow the state of the running

Now FastQC is creating a HTML file for each sequencing file. It is better to create a report for all of them. MultiQC is useful for this:


submitMultiQC.sh

<input type=button class=hideshow></input>
```{MultiQC}
#!/bin/bash -l

set -e
# use set -ex for debugging instead

proj=u2018012
mail=francisco.gil.munoz@slu.se
in=/mnt/picea/projects/dateplum/rgarcia/persimmon-rootstocks-salinity-tolerance/
out=/mnt/picea/projects/dateplum/rgarcia/persimmon-rootstocks-salinity-tolerance/multiqc

if [ ! -d $out ]; then
	mkdir -p $out
fi

module load bioinfo-tools multiqc

sbatch --mail-user=$mail -o $in/multiqc.out -e $in/multiqc.err \
-A $proj $UPSCb/pipeline/runMultiQC.sh $in $out
```

```{runMultiQC}
#!/bin/bash
#SBATCH -p core
#SBATCH -n 1
#SBATCH --mail-type=ALL
#SBATCH -t 02:00:00

## stop on error but be verbose
set -ex

##
#  Run MultiQC 
usage(){
  echo >&2 \
  "Usage: $(basename $0) <analysis directory> <output directory>"
  exit 1
}

## arguments
if [ $# -lt 2 ]; then
   echo "This script takes two arguments"
   usage
fi

## input file
if [ ! -d $1 ]; then
	echo "The first argument needs to be an existing analysis directory."
	usage
fi

if [ ! -d $2 ]; then
	echo "The second argument needs to be an existing output directory."
	usage
fi

## start
multiqc -o $2 $1
```

The program generates an HTML file with a summary of the reports generated by FastQC but for all the files.


## Remove Ribosomal RNA

We have observed that the GC content is a little bit high, we also observed some "shoulders" in the high GC zone on the GC content graphic. This indicates a contamination with ribosomal RNA.

Sortmerna is a tool designed to remove sequences that contain ribosomal RNA by comparing K-mers with a database (High computing requirements)

submitSortmerna.sh

<input type=button class=hideshow></input>
```{Sortmerna}
#!/bin/bash -l

proj=u2018012
tmp=/mnt/picea/tmp/fmunoz
mail="francisco.gil.munoz@slu.se"
out=/mnt/picea/projects/dateplum/rgarcia/persimmon-rootstocks-salinity-tolerance/sortmerna
in=/mnt/picea/projects/dateplum/rgarcia/persimmon-rootstocks-salinity-tolerance/raw

module load bioinfo-tools
module load sortmerna

for f in `find $in -name "*_[1,2].fq.gz" `; do echo "${f//_[1,2].fq.gz/}" ; done | sort | uniq | while read line;
do 
fnam=`basename $line`
sbatch -A $proj --mail-user $mail -e $out/$fnam.err -o $out/$fnam.out -J smr-$fnam $UPSCb/pipeline/runSortmerna.sh \
$out $tmp -m ${line}_1.fq.gz ${line}_2.fq.gz
done

```

```{runSortmerna}
#!/bin/bash
#SBATCH -p node
## for large files
## we don't need the proc but the mem
## we could give that as param
#SBATCH -n 20
## time too for large files
#SBATCH -t 24:00:00
#SBATCH --mail-type=ALL
## mail-user and A have to be set in the submit script

## stop on error
set -e

## be verbose and extend the commands
set -x

## check the options if any
KEEP=1
useMtSSU=0
UNPAIRED=0
PROC=20
DBS=

## source functions
source $UPSCb/src/bash/functions.sh

## usage
export USAGETXT="
	Usage: runSortmerna.sh [option] <out dir> <tmp dir> <forward fastq.gz> <reverse fastq.gz>
	
	Options:
                -d define your dbs (semi-colon separated)
                -k drop the rRNA (only for v1.9, default to keep them)
                -m run against mtSSU in addition (only for v1.9)
                -p number of threads to be used (default $PROC)
                -u single end data (in that case only the forward fastq is needed)

         Note:
               1) The SORTMERNA_DBS environment variable needs to be set
               2) Only SortMeRna version 1.9 and 2.x are supported (2.x is default)
               3) -m is not applicable if -d is set
               4) the 2nd argument is just a place holder on UPPMAX, it is automatically replaced by the node local tmp
"

## then check for availability
# tool=`which sortmerna 2>/dev/null`
# if [ ! -z $tool ] && [ -f $tool ] && [ -x $tool ]; then
#   echo "sortmerna available"
# else
#   echo "ERROR: INSTALL SortMeRna"
#   usage
# fi

## check for sortmerna version
is1dot9=`sortmerna --version 2>&1 | grep version | grep 1.9 | wc -c`
is2dotx=`sortmerna --version 2>&1 | grep "version 2." | wc -c`

if [ $is1dot9 == 0 ] && [ $is2dotx  == 0 ]; then
  abort "Only version 1.9 and 2.x are supported"
fi

## get the options
while getopts d:kmp:u option
do
        case "$option" in
      d) DBS=$OPTARG;;
	    k) KEEP=0;;
	    m) useMtSSU=1;;
	    p) PROC=$OPTARG;;
	    u) UNPAIRED=1;;
		\?) ## unknown flag
		abort;;
        esac
done
shift `expr $OPTIND - 1`

##
echo Setting up

## set some env var
## this location is not in Git anymore!
## it has to be downloaded by the user
## check the ethylene-insensitive project submitter to see
## how to set that up
if [ -z $SORTMERNA_DBS ]; then
    abort "You need to set your SORTMERNA_DBS environment variable"
fi

## set the default dbs
if [ ! -z $DBS ]; then
  dbs=${DBS//;/ }
  dbNum=`echo $DBS | awk -F";" '{print NF}'`
else
  if [ $is2dotx != 0 ]; then
    db5s=$SORTMERNA_DBS/rRNA_databases/rfam-5s-database-id98.fasta,$SORTMERNA_DBS/index/rfam-5s-database-id98
    db58s=$SORTMERNA_DBS/rRNA_databases/rfam-5.8s-database-id98.fasta,$SORTMERNA_DBS/index/rfam-5.8s-database-id98
    db16sa=$SORTMERNA_DBS/rRNA_databases/silva-arc-16s-id95.fasta,$SORTMERNA_DBS/index/silva-arc-16s-id95
    db16s=$SORTMERNA_DBS/rRNA_databases/silva-bac-16s-id90.fasta,$SORTMERNA_DBS/index/silva-bac-16s-id90
    db18s=$SORTMERNA_DBS/rRNA_databases/silva-euk-18s-id95.fasta,$SORTMERNA_DBS/index/silva-euk-18s-id95
    db23sa=$SORTMERNA_DBS/rRNA_databases/silva-arc-23s-id98.fasta,$SORTMERNA_DBS/index/silva-arc-23s-id98
    db23s=$SORTMERNA_DBS/rRNA_databases/silva-bac-23s-id98.fasta,$SORTMERNA_DBS/index/silva-bac-23s-id98
    db28s=$SORTMERNA_DBS/rRNA_databases/silva-euk-28s-id98.fasta,$SORTMERNA_DBS/index/silva-euk-28s-id98
    dbs="$db5s:$db58s:$db16sa:$db16s:$db18s:$db23sa:$db23s:$db28s"
  else
    db5s=$SORTMERNA_DBS/rRNA_databases/rfam-5s-database-id98.fasta
    db58s=$SORTMERNA_DBS/rRNA_databases/rfam-5.8s-database-id98.fasta
    db16sa=$SORTMERNA_DBS/rRNA_databases/silva-arc-16s-id95.fasta
    db16s=$SORTMERNA_DBS/rRNA_databases/silva-bac-16s-id85.fasta
    db18s=$SORTMERNA_DBS/rRNA_databases/silva-euk-18s-id95.fasta
    db23sa=$SORTMERNA_DBS/rRNA_databases/silva-arc-23s-id98.fasta
    db23s=$SORTMERNA_DBS/rRNA_databases/silva-bac-23s-id98.fasta
    db28s=$SORTMERNA_DBS/rRNA_databases/silva-euk-28s-id98.fasta
    dbNum=8
    dbs="$db5s $db58s $db16sa $db16s $db18s $db23sa $db23s $db28s"
  fi

  ## Add the mtSSU
  if [ $is1dot9 != 0 ] && [ $useMtSSU == 1 ]; then
    mtSSU=$SORTMERNA_DBS/rRNA_databases/mtSSU_UCLUST-95-identity.fasta
    dbs="$dbs $mtSSU"
    dbNum=9
  fi
fi

##
echo Checking

## we get two dir and two files as input
if [ $UNPAIRED == 0 ]; then
    if [ $# != 4 ]; then
	abort "This function takes two directories and two files as arguments"
    fi
else
    if [ $# != 3 ]; then
	abort "This function takes two directories and one file as argument"
    fi
fi

if [ ! -d $1 ]; then
    abort "The first argument needs to be an existing directory"
fi

if [ ! -d $2 ]; then
    abort "The second argument needs to be an existing directory"
fi

## UPPMAX hack
if [ ! -z $SNIC_RESOURCE ]; then
  tmp=/scratch/$SLURM_JOB_ID
  # even uglier hack; should be fixed as soon as uppmax add the merge scripts to the module file
  export PATH=/sw/apps/bioinfo/SortMeRNA/2.1b/src_milou/sortmerna-2.1b/scripts:$PATH
else
  tmp=$2
fi
echo TMP: $tmp

## 
echo Gunzipping

## unzip the files
if [ ! -f $3 ]; then
    abort "The third argument needs to be an existing fastq.gz file"
fi
f1=`basename ${3//.gz/}`

if [ $UNPAIRED == 0 ]; then
    if [ ! -f $4 ]; then
	abort "The forth argument needs to be an existing fastq.gz file"
    fi
    f2=`basename ${4//.gz/}`
fi

## decompress them
if [ ! -f $tmp/$f1 ]; then
    gunzip -c $3 > $tmp/$f1
fi
if [ $UNPAIRED == 0 ]; then
    if [ ! -f $tmp/$f2 ]; then
	gunzip -c $4 > $tmp/$f2
    fi
fi

## interleave them
fm=`basename ${3//.f*q.gz/}`
if [ $UNPAIRED == 0 ]; then
  merge-paired-reads.sh $tmp/$f1 $tmp/$f2 $tmp/$fm
fi

##
if [ $UNPAIRED == 0 ]; then
    echo Pre-cleaning
    rm -f $tmp/$f1 $tmp/$f2
else
    echo "TODO: Cleaning needs implementing for single end sequencing"
fi

##
echo Sorting

## PE
if [ $UNPAIRED == 0 ]; then
    fo=`basename ${3//_[1,2].f*q.gz/_sortmerna}`
else
    fo=`basename ${3//.f*q.gz/_sortmerna}`
fi

## check the options
opt="-a $PROC"

if [ $KEEP == 1 ] && [ $is1dot9 != 0 ]; then
  opt="$opt --bydbs --accept $tmp/${fo}_rRNA"
fi 

## run
if [ $UNPAIRED == 0 ]; then
  if [ $is2dotx != 0 ]; then
    sortmerna --ref $dbs --reads $tmp/$fm --other $tmp/$fo --log --paired_in --fastx $opt --sam --num_alignments 1 --aligned $tmp/${fo}_rRNA
  else
    sortmerna -n $dbNum --db $dbs --I $tmp/$fm --other $tmp/$fo --log $1/$fo --paired-in $opt
  fi  
else
  if [ $is2dotx != 0 ]; then
    sortmerna --ref $dbs --reads $tmp/$f1 --other $1/$fo --log $opt --sam --fastx --num_alignments 1 --aligned $tmp/${fo}_rRNA
  else
    sortmerna -n $dbNum --db $dbs --I $tmp/$f1 --other $1/$fo --log $1/$fo $opt
  fi
fi

## deinterleave it
if [ $UNPAIRED == 0 ]; then
    ## sortmerna get confused by dots in the filenames
    if [ ! -f $tmp/$fo.fastq ]; then
	    mv $tmp/$fo.* $tmp/$fo.fastq
    fi
    unmerge-paired-reads.sh $tmp/$fo.fastq $1/${fo}_1.fq $1/${fo}_2.fq
fi

## cleanup
echo Post-Cleaning

if [ $is2dotx != 0 ]; then
  ## mv the rRNA, fastq and log back
  mv $tmp/${fo}_rRNA.* $1
fi

## rm the tmp
if [ $UNPAIRED == 0 ]; then
    rm -f $tmp/$fm $tmp/$fo.fastq
else
    rm -f $tmp/$f1
fi

## deinterleave the rest if needed
if [ $KEEP == 1 ]; then
    if [ $UNPAIRED == 0 ]; then
	find $tmp -name "${fo}_rRNA*" -print0 | xargs -0 -I {} -P 6 sh -c 'unmerge-paired-reads.sh $0 $1/`basename ${0//.fastq/_1.fq}` $1/`basename ${0//.fastq/_2.fq}`' {} $1
    fi
fi

## keep that as a reminder if that happens again
## sortmerna get confused by the dots as well...
## echo Validating
if [ $UNPAIRED == 1 ]; then
    if [ ! -f $1/$fo.fastq ] && [ ! -f $1/$fo.fq ] ; then
        abort "Could not find the output file. Check the files: $1/$fo"
        #find $1 -name "$fo*" | grep -v *.err | grep -v *.out | xargs
        #mv $1/$fo.$1/$fo.fq
    fi
fi

## 
echo Gzipping

## compress the output files
if [ $UNPAIRED == 0 ]; then
  find $1 -name "${fo}*.fq" -print0 | xargs -0 -I {} -P $PROC gzip -f {}
else
  if [ -f $1/$fo.fastq ]; then
    gzip -c $1/$fo.fastq > $1/$fo.fq.gz
    rm $1/$fo.fastq
  else
    gzip $1/$fo.fq
  fi
fi

# compress the 2.X new files (sam and _rRNA)
if [ $is2dotx != 0 ]; then
  find $1 -name "${fo}_rRNA.[f,s]*" -print0 | xargs -0 -I {} -P $PROC gzip -f {}
fi

##
echo Done

```

In this case, **IT IS** important to distinguish between forward and reverse sequences. Otherwise if we remove a sequence that is shown to be ribosomal, the file will lose the parity between forward an reverse.

TIP: if you have a mistake you can cancel the process by typing 
```{scancel}
scancel -u(user) {username or jobID} 
```

##Trimmomatic

Trimmomatic will remove automatically low quality sequences according to the specified parameters.

submitTrimmomatic.sh

<input type=button class=hideshow></input>
```{trimmomatic}
#!/bin/bash -l

## stop on error
set -e
# use set -ex for debugging instead

## args
mail="francisco.gil.munoz@slu.se"
proj=u2018012
  

## create the in and out dir
in=/mnt/picea/projects/dateplum/rgarcia/persimmon-rootstocks-salinity-tolerance/raw
out=/mnt/picea/projects/dateplum/rgarcia/persimmon-rootstocks-salinity-tolerance/trimmomatic
mkdir -p $out

## select all files

for f in `find $in -name "*.fq.gz"`; do echo "$(basename ${f//_[1,2].fq.gz/})" ; done | sort | uniq | while read line;
do

nam=`basename $line`
 sbatch -A $proj --mail-user $mail -e $out/$line.err -o $out/$line.out -J Trim-$line\
 $UPSCb/pipeline/runTrimmomatic.sh $in/${line}_1.fq.gz $in/${line}_2.fq.gz $out
done
```

```{runTrimmomatic}
#!/bin/bash
#SBATCH -p node 
#SBATCH -n 20
#SBATCH -t 2-00:00:00
#SBATCH --mail-type=ALL

## abort on error
set -ex

## TODO add an option for no clipping!

## usage
usage(){
echo >&2 \
"Usage: 
    Paired end: $0 <fwd fastq file> <rev fastq file> <output dir> [trimming options]
    Single end: $0 -s <fastq file> <output dir> [trimming options]

Options:
    -c      clipping file and settings
    -p      number of threads to use
    -q      use illumina quality (+64 offset), default to sanger now (+33 offset)!
    -s      single end reads
    -t      add a trim log (defaut no trimlog anymore)
    -v      verbose output


Trimming options:
    Trimming defaults to 'SLIDINGWINDOW:5:20 MINLEN:50'
    If you change the default, you need to provide the COMPLETE trimming option again!!!
    e.g. to use a 30 quality threshold for the sliding window, provide: SLIDINGWINDOW:5:30 MINLEN:50.
    Clipping defaults to 'ILLUMINACLIP:\"$TRIMMOMATIC_HOME/adapters/TruSeq3-PE-2.fa\":2:30:10'

"
    exit 1
}

## check env var
if [ -z $TRIMMOMATIC_HOME ]; then
    echo "The TRIMMOMATIC_HOME environment variable needs to be set. Load the T(t)rimmomatic module"
    usage
fi

## options
clip=
single_end=0
phred="-phred33"
thread=20
trimlog=0
verbose=0
while getopts "c:p:qstv" opt; do
    case $opt in
	c) clip=$OPTARG;;
	p) thread=$OPTARG;;
	q) phred="-phred64";;
        s) single_end=1;;
	t) trimlog=1;;
	v) verbose=1;;
        \?) usage;;
    esac
done
shift `expr $OPTIND - 1`

if [ $verbose -eq 1 ]; then
    echo "Options are to use $thread CPUs"
    if [ $single_end -eq 0 ]; then
	echo "for paired-end trimming."
    else
	echo "for single-end trimming."
    fi
fi

## check the arguments
if [ $single_end -eq 0 -a $# -lt 3 ] || [ $single_end -eq 1 -a $# -lt 2 ]; then
    echo "Given the provided option, the number of argument is incorrect."
    usage
fi

## the clip default
if [ -z $clip ]; then
    if [ $single_end -eq 0 ]; then
	clip=ILLUMINACLIP:$TRIMMOMATIC_HOME/adapters/TruSeq3-PE-2.fa:2:30:10
    else
	clip=ILLUMINACLIP:$TRIMMOMATIC_HOME/adapters/TruSeq3-SE.fa:2:30:10
    fi
fi

## the trim default
trim="SLIDINGWINDOW:5:20 MINLEN:50"

## check file 1
if [ ! -f "$1" ]; then
    echo "The first argument must be the valid file name of the forward fastq file."
    usage
fi
fwd=$1
shift

if [ $verbose -eq 1 ]; then
    echo "Forward file is $fwd"
fi

## create the pattern
if [ $single_end -eq 0 ]; then
    pattern=`basename ${fwd//_1.f*q.gz//}`
else
    pattern=`basename ${fwd//.f*q.gz//}`
fi

## Paired end
if [ $single_end -eq 0 ]; then

    ## check file 2
    if [ ! -f "$1" ]; then
        echo "The second argument must be the valid file name of the reverse fastq file."
        usage
    fi
    rev=$1
    shift

    if [ $verbose -eq 1 ]; then
	echo "Reverse file is $rev"
    fi
fi

## check dir
if [ ! -d "$1" ]; then
    echo $1
    echo "The third argument must be an existing directory."
    usage
fi
out=$1
shift

if [ $verbose -eq 1 ]; then
    echo "Output dir is $out"
fi

if [ $verbose -eq 1 ]; then
    echo "Phred scale is $phred"
fi

log=
if [ $trimlog -eq 1 ]; then
    log=-trimlog $out/$pattern.log
    echo "Trim log is $log"
fi

if [ $# -gt 0 ]; then
    trim=$@
fi

if [ $verbose -eq 1 ]; then
    echo "Trimming parameters are $trim"
fi

## PE
if [ $single_end -eq 0 ]; then
    
    ## start the job
    java -jar $TRIMMOMATIC_HOME/trimmomatic.jar PE -threads $thread $phred $log $fwd $rev $out/${pattern}_trimmomatic_1.fq $out/${pattern}_unpaired_1.fq $out/${pattern}_trimmomatic_2.fq $out/${pattern}_unpaired_2.fq $clip $trim

    if [ $trimlog -eq 1 ]; then
	printf "%s\0%s\0%s\0%s\0%s" $out/${pattern}_trimmomatic_1.fq $out/${pattern}_unpaired_1.fq $out/${pattern}_trimmomatic_2.fq $out/${pattern}_unpaired_2.fq $out/$pattern.log | xargs -0 -I {} -P $thread gzip -f {}
    else
	printf "%s\0%s\0%s\0%s" $out/${pattern}_trimmomatic_1.fq $out/${pattern}_unpaired_1.fq $out/${pattern}_trimmomatic_2.fq $out/${pattern}_unpaired_2.fq | xargs -0 -I {} -P $thread gzip -f {}
    fi

else
    java -jar $TRIMMOMATIC_HOME/trimmomatic.jar SE -threads $thread $phred $log $fwd $out/${pattern}_trimmomatic.fq $clip $trim
    if [ $trimlog -eq 1 ]; then
	printf "%s\0%s" $out/${pattern}_trimmomatic.fq $out/$pattern.log | xargs -0 -I {} -P $thread gzip -f {}
    else
	gzip -f $out/${pattern}_trimmomatic.fq	
    fi
fi


```

Then it is a good idea to run FastQC for checking how it went trough the cleaning.

MultiQC will notice about all the files and then will made a report about the cleaning



##De novo assembly

We will use Trinity for the assembly. In this part we are going to run it inside a container, but the use is the same outside from it.

First we need to create a txt file with the experiment conditions separated by tabulation:

```{samples.txt}
cond_A    cond_A_rep1    A_rep1_left.fq    A_rep1_right.fq
cond_A    cond_A_rep2    A_rep2_left.fq    A_rep2_right.fq
cond_B    cond_B_rep1    B_rep1_left.fq    B_rep1_right.fq
cond_B    cond_B_rep2    B_rep2_left.fq    B_rep2_right.fq
```

See more: https://github.com/trinityrnaseq/trinityrnaseq/wiki/Running-Trinity

Then we can run the script:

<input type=button class=hideshow></input>
```{submitTrinity}
#!/bin/bash -l

sbatch -e /mnt/picea/projects/dateplum/rgarcia/persimmon-rootstocks-salinity-tolerance/trinity.err \
-o /mnt/picea/projects/dateplum/rgarcia/persimmon-rootstocks-salinity-tolerance/trinity.out \
$UPSCb/projects/persimmon/pipeline/runTrinity.sh

```


```{runTrinity}

#! /bin/bash -l
#SBATCH -p core -n 48 --mem=300G -t 2-00:00:00
#SBATCH --mail-type=ALL --mail-user=francisco.gil.munoz@slu.se
#SBATCH -A u2018012
#
# module load bioinfo-tools
# module load trinity

set -ex

singularity exec --bind /mnt:/mnt /mnt/picea/projects/singularity/trinity-2.8.3.1.simg \
Trinity --seqType fq --max_memory 300G --samples_file $UPSCb/projects/persimmon/pipeline/samples.txt \
--CPU 30 --output /mnt/picea/projects/dateplum/rgarcia/persimmon-rootstocks-salinity-tolerance/trinity \
--SS_lib_type RF 

```

## Expression quantification

Once we have assembled the transcriptome, we will use Trinity to assign reads to unigenes. Salmon is a strong algorithm based on K-mers more robust than the previous ones. 

Salmon needs to index the transcriptome file from its K-mers. A first run is needed to build the index with only one sample with the option --prep_reference. Once done the rest of the samples will use the index.

<input type=button class=hideshow></input>
```{submitExpression}
#!/bin/bash -l

set -ex

proj=u2018012
tmp=/mnt/picea/tmp/fmunoz/expq
mail="francisco.gil.munoz@slu.se"
out=/mnt/picea/projects/dateplum/rgarcia/persimmon-rootstocks-salinity-tolerance/expressionQ
in=/mnt/picea/projects/dateplum/rgarcia/persimmon-rootstocks-salinity-tolerance/raw
trans=/mnt/picea/projects/dateplum/rgarcia/persimmon-rootstocks-salinity-tolerance/trinity/Trinity.fasta

#Creating directories

if [ ! -d $tmp ]; then
	mkdir -p $tmp
fi

if [ ! -d $out ]; then
	mkdir -p $out
fi

#Loop for Expression quantification
i=1 #i=1 for indexing
for f in `find $in -name "*_[1,2].fq.gz" `; do echo "${f//_[1,2].fq.gz/}" \
; done | sort | uniq | while read line;
do 
  fnam=`basename $line`
  if [ "$i" -eq "1" ]; then
    jobid=$(sbatch -A $proj --mail-user $mail -e $out/$fnam.err -o $out/$fnam.out \
  -J smr-$fnam $UPSCb/projects/persimmon/pipeline/runExpressionq.sh -p ${line}_1.fq.gz \
  ${line}_2.fq.gz $trans $tmp $out)
  i=0
  else
  sbatch -A $proj --mail-user $mail -e $out/$fnam.err -o $out/$fnam.out \
  -J smr-$fnam -d afterok:${jobid//[^0-9]/}\
  $UPSCb/projects/persimmon/pipeline/runExpressionq.sh ${line}_1.fq.gz \
  ${line}_2.fq.gz $trans $tmp $out
  fi

done

```


```{runExpression}

#! /bin/bash -l
#SBATCH -p core -n 1 -t 2-00:00:00
#SBATCH --mail-type=ALL --mail-user=francisco.gil.munoz@slu.se
#SBATCH -A u2018012
#
# module load bioinfo-tools
# module load trinity

set -ex

#Calling for options 
# $@
# $1
# $2
# $3
# $4

# usage text

export USAGETXT=\
"
	Usage: $0 [options] <forward file> <reverse file> <transcriptome fasta> <temporal directory> <output directory>
  
  Options: 
    -p prepare the reference (default not to)
"
# load the helper (has functions that summarizes some functions)
source $UPSCb/src/bash/functions.sh

# default

PREP=
CPU=1

# Options. We are defining the --prep_reference Trinity option as a variable to be written in the command

while getopts hp option
do
  case "$option" in
      h) usage;;
      p) PREP="--prep_reference";;
      ?) usage;;
  esac
done
shift `expr $OPTIND - 1`


# Defining variables and testing for them ($number is each variable call in the order
# of they were defined after calling the script)

if [ "$#" -ne "5" ]; then
  abort "Number of variables different than expected"
fi

if [ ! -f $1 ]; then
  abort "Forward file not found or not a fastq file"
fi

if [ ! -f $2 ]; then
  abort "Reverse file not found or not a fastq file"
fi

if [ ! -f $3 ]; then
  abort "Transcriptome file not found or not a fasta file"
fi

if [ ! -d $4 ]; then
  abort "Temporal folder not found or not available"
fi

if [ ! -d $5 ]; then
  abort "Output folder not found or not available"
fi


#-d is a directory

#Unzipping files
fwd=$4/$(basename ${1/.gz/})
rev=$4/$(basename ${2/.gz/})
gunzip -c $1 > $fwd 
gunzip -c $2 > $rev

# run
singularity exec --bind /mnt:/mnt /mnt/picea/projects/singularity/trinity-2.8.3.1.simg \
/usr/local/bin/trinityrnaseq/util/align_and_estimate_abundance.pl \
--seqType fq --left $fwd --right $rev --transcripts $3 \
--est_method salmon --trinity_mode --output_dir $5 --thread_count $CPU $PREP

rm $fwd $rev


```

## Assembly Quality check

One of the best ways to check the quality of the assembly is to use the Expression vs N50 parameter (https://github.com/trinityrnaseq/BerlinTrinityWorkshop2018/wiki/assembly_quality_assessment). It consist on a representation of the N50 contig vs the most expressed genes.


<input type=button class=hideshow></input>
```{submitExN50}

#!/bin/bash -l

set -ex

proj=u2018012
mail="francisco.gil.munoz@slu.se"
out=/mnt/picea/projects/dateplum/rgarcia/persimmon-rootstocks-salinity-tolerance/trinity
in=/mnt/picea/projects/dateplum/rgarcia/persimmon-rootstocks-salinity-tolerance/trinity
trans=/mnt/picea/projects/dateplum/rgarcia/persimmon-rootstocks-salinity-tolerance/trinity/Trinity.fasta

sbatch -A $proj --mail-user $mail -e $out/ExN50.err -o $out/ExN50.out \
$UPSCb/projects/persimmon/pipeline/runExN50.sh $in/Trinity_trans.isoform.TMM.EXPR.matrix \
$trans $out

```

```{runExN50}

#! /bin/bash -l
#SBATCH -p core -n 1 -t 01:00:00
#SBATCH --mail-type=ALL --mail-user=francisco.gil.munoz@slu.se
#SBATCH -A u2018012
#
# module load bioinfo-tools
# module load trinity

set -ex

export USAGETXT=\
"
Usage: $0 <Transcripts matrix> <transcriptome fasta> <output directory>

"
# load the helper (has functions that summarizes some functions)
source $UPSCb/src/bash/functions.sh


# Options. We are defining the --prep_reference Trinity option as a variable to be written in the command

while getopts hp option
do
case "$option" in
h) usage;;
?) usage;;
esac
done
shift `expr $OPTIND - 1`


# Defining variables and testing for them ($number is each variable call in the order
# of they were defined after calling the script)

if [ "$#" -ne "3" ]; then
abort "Number of variables different than expected"
fi

if [ ! -f $1 ]; then
abort "Expression matrix not found"
fi

if [ ! -f $2 ]; then
abort "Transcriptome file not found or not a fasta file"
fi

if [ ! -d $3 ]; then
abort "Output folder not found or not available"
fi


#-d is a directory



singularity exec --bind /mnt:/mnt /mnt/picea/projects/singularity/trinity-2.8.3.1.simg \
/usr/local/bin/trinityrnaseq/util/misc/contig_ExN50_statistic.pl \
$1 $2 | tee $3\ExN50.stats

```

The output file has 3 columns. One for expression level, other for N50 contig length and other for number of genes. The file should be represented as a curve with the expression level on the X axis and the N50 contig on the Y axis.

A good transcriptome assembly should have a N50 "peak" on the curve. A higher level of expression of the peak correlates with a better quality of the assembly.

## Expression matrix of all the samples

Once we have the transcriptome and the expression levels, is time to build a matrix for knowing the expression level of each unigene in each sample.

<input type=button class=hideshow></input>
```{submitExpressionMatrix}

#!/bin/bash -l

set -ex

proj=u2018012
mail="francisco.gil.munoz@slu.se"
out=/mnt/picea/projects/dateplum/rgarcia/persimmon-rootstocks-salinity-tolerance/expressionQ
in=/mnt/picea/projects/dateplum/rgarcia/persimmon-rootstocks-salinity-tolerance/expressionQ
trans=/mnt/picea/projects/dateplum/rgarcia/persimmon-rootstocks-salinity-tolerance/trinity

sbatch -A $proj --mail-user $mail -e $out/ExpressionMatrix.err -o $out/ExpressionMatrix.out \
-J EMatrix $UPSCb/projects/persimmon/pipeline/runExpressionMatrixManual.sh $in $trans 
  
# Every variable passed after the .sh file is sended to the other script. They must be catched in the run script
# with the written order as $1, $2,... $n

```

```{runExpressionMatrixManual}
#! /bin/bash -l
#SBATCH -p core -n 30 --mem=50G -t 2-00:00:00
#SBATCH --mail-type=ALL --mail-user=francisco.gil.munoz@slu.se
#SBATCH -A u2018012
#
# module load bioinfo-tools
# module load trinity

set -ex

#Calling for options 
# $@
# $1
# $2
# $3
# $4

# usage text

export USAGETXT=\
"
	Usage: $0  <expression quantification folder> <transcriptome folder> 
  
"
# load the helper (has functions that summarizes some functions)
source $UPSCb/src/bash/functions.sh

# default

CPU=30

# Options. We are defining the --prep_reference Trinity option as a variable to be written in the command

while getopts hp option
do
  case "$option" in
      h) usage;;
      p) PREP="--prep_reference";;
      ?) usage;;
  esac
done
shift `expr $OPTIND - 1`


# Defining variables and testing for them ($number is each variable call in the order
# of they were defined after calling the script)

if [ "$#" -ne "2" ]; then
  abort "Number of variables different than expected"
fi

if [ ! -d $1 ]; then
  abort "Quantification files not found"
fi

if [ ! -d $2 ]; then
  abort "Transcriptome folder not found"
fi


#-d is a directory



# run
singularity exec --bind /mnt:/mnt /mnt/picea/projects/singularity/trinity-2.8.3.1.simg \
/usr/local/bin/trinityrnaseq/util/abundance_estimates_to_matrix.pl \
--est_method salmon  --out_prefix Trinity_trans \
--name_sample_by_basedir \
 $1/HC1/quant.sf \
 $1/HC2/quant.sf \
 $1/HC3/quant.sf \
 $1/HT1/quant.sf \
 $1/HT2/quant.sf \
 $1/HT3/quant.sf \
 $1/HS1/quant.sf \
 $1/HS2/quant.sf \
 $1/HS3/quant.sf \
 $1/RC1/quant.sf \
 $1/RC2/quant.sf \
 $1/RC3/quant.sf \
 $1/RT1/quant.sf \
 $1/RT2/quant.sf \
 $1/RT3/quant.sf \
 $1/RS1/quant.sf \
 $1/RS2/quant.sf \
 $1/RS3/quant.sf \
--gene_trans_map $2/Trinity.fasta.gene_trans_map

```

<script>
$( "input.hideshow" ).each( function ( index, button ) {
  button.value = 'Hide runScript';
  $( button ).click( function () {
    var target = this.nextSibling ? this : this.parentNode;
    target = target.nextSibling.nextSibling.nextSibling.nextSibling;
    if ( target.style.display == 'block' || target.style.display == '' ) {
      target.style.display = 'none';
      this.value = 'Show runScript';
    } else {
      target.style.display = 'block';
      this.value = 'Hide runScript';
    }
  } );
} );
</script>